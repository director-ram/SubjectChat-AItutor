# ===== Web =====
VITE_API_BASE_URL=http://localhost:8000

# ===== API =====
ENV=local
DATABASE_URL=postgresql+psycopg://subjectchat:subjectchat@localhost:5432/subjectchat
REDIS_URL=redis://localhost:6379/0

# LLM (optional). If unset, API runs in stub mode.
OPENAI_API_KEY=
# For local Llama 3.2 via LM Studio (OpenAI-compatible server), use:
# OPENAI_BASE_URL=http://localhost:1234/v1
OPENAI_BASE_URL=
# Model name must match what your local server exposes.
# Example (LM Studio): llama-3.2-3b-instruct
# Example (Ollama OpenAI-compatible): llama3.2
OPENAI_MODEL=llama-3.2-3b-instruct
